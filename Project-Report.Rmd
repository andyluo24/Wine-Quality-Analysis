---
title: "STAT 420: Final Project"
date: "12/10/2020"
output:
  html_document:
    theme: readable
    toc: yes
---

# Introduction

## Data Description

Two [datasets](https://archive.ics.uci.edu/ml/datasets/wine+quality) from the Machine Learning Repository of UCI will be used for this project.

The first dataset "winequality-red" contains the red wine data in the northern Portugal area, while the second dataset "winequality-white" contains the white wine data. 

For analysis purposes, we classify all the observations based on their color types and merge them into one dataset.

The complete dataset has 6497 observations with 13 variables. 

Among the 13 variables, 12 variables are numeric attributes and 1 variable is a categorical attribute.

Numeric attributes: 

- `fixed.acidity`: Most acids involved with wine or fixed or nonvolatile (do not evaporate readily).
- `volatile.acidity`: The amount of acetic acid in wine, which at too high of levels can lead to an unpleasant, vinegar taste.
- `citric.acid`: Found in small quantities, citric acid can add 'freshness' and flavor to wines.
- `residual.sugar`: The amount of sugar remaining after fermentation stops.
- `chlorides`: The amount of salt in the wine.
- `free.sulfur.dioxide`: The free form of SO2 exists in equilibrium between molecular SO2 (as a dissolved gas) and bisulfite ion.
- `total.sulfur.dioxide`: Amount of free and bound forms of S02;in low concentrations, SO2 is mostly undetectable in wine, but at free SO2 concentrations over 50 ppm, SO2 becomes evident in the nose and taste of wine.
- `density`: The density of water is close to that of water depending on the percent alcohol and sugar content.
- `pH`: Describes how acidic or basic a wine is on a scale from 0 (very acidic) to 14 (very basic);most wines are between 3-4 on the pH scale.
- `sulphates`: A wine additive which can contribute to sulfur dioxide gas (S02) levels, which acts as an antimicrobial and antioxidant.
- `alcohol`: The percent alcohol content of the wine.
- `quality`: Output variable.   

Categorical attributes:

- `Type`: Red / White.

## Project Description

Wine, as one type of alcohol, has a total consumption of 966 million in the US in 2018. 
  
Therefore, we find it may be interesting to discover the relationship between wine quality and other attributes. 
  
Then we will build a model to predict the wine quality based on those attributes. 
  
In this project, we will use "Quality" as the response variable and all other attributes as predictor variables to discover the most appropriate model.

# Methods

## Data Preprocessing

```{r dp0, message = FALSE}
# Load required packages
library(tidyverse)
library(leaps)
library(faraway)
library(caret)
library(e1071)
library(plyr)
# Set seed for report consistency
set.seed(420)
```

```{r dp1}
# Import two datasets
redwine = read.csv("winequality-red.csv")
whitewine  = read.csv("winequality-white.csv")
# Add Classification "red" and "white" and merge them as one dataset
redwine$type = "red"
whitewine$type = "white"
wine = rbind(redwine, whitewine)
str(wine)
```

There are 6497 observations with 13 variables in this combined dataset.

Among 13 variables, 12 variables are numeric attributes and 1 variable is categorical attribute.

Since the original datasets are clean-version data, we don't need to perform further data cleansing.

Next, we randomly chose 80% of the data as the training data where we apply different models on. The 20% of the data is validation data, which is used to test the accuracy of our final model. 

```{r dp2}
# Cross-validation
# 80% of the dataset for training purpose and 20% of the dataset for testing purpose
wine$type = as.factor(wine$type)
random_sample = createDataPartition(wine$quality, p = 0.8, list = FALSE)
training_data = wine[random_sample, ]
testing_data = wine[-random_sample, ]
```

## Simple Linear Regression Model

First, we try to use simple linear regression to check if the wine quality is closely connected to one attribute.     
 
Here is the graph and regression line for the 10 simple linear regression model.

```{r}
model1 = lm(quality ~ free.sulfur.dioxide, data = training_data)
plot(quality ~ free.sulfur.dioxide, data = training_data, xlab = "Free Sulfur Dioxide", ylab = "Quality of Wines")
grid()
curve(predict(model1, data.frame(free.sulfur.dioxide = x), type = "response"), 
      add = TRUE, col = "dodgerblue", lty = 2)

model2 = lm(quality ~ total.sulfur.dioxide, data = training_data)
plot(quality ~ total.sulfur.dioxide, data = training_data, xlab = "Total Sulfur Dioxide", ylab = "Quality of Wines")
grid()
curve(predict(model2, data.frame(total.sulfur.dioxide = x), type = "response"), 
      add = TRUE, col = "dodgerblue", lty = 2)

model3 = lm(quality ~ fixed.acidity, data = training_data)
plot(quality ~ fixed.acidity, data = training_data, xlab = "fixed.acidity", ylab = "Quality of Wines")
grid()
curve(predict(model3, data.frame(fixed.acidity = x), type = "response"), 
      add = TRUE, col = "dodgerblue", lty = 2)

model4 = lm(quality ~ volatile.acidity, data = training_data)
plot(quality ~ volatile.acidity, data = training_data, xlab = "volatile.acidity", ylab = "Quality of Wines")
grid()
curve(predict(model4, data.frame(volatile.acidity = x), type = "response"), 
      add = TRUE, col = "dodgerblue", lty = 2)

model5 = lm(quality ~ residual.sugar, data = training_data)
plot(quality ~ residual.sugar, data = training_data, xlab = "residual.sugar", ylab = "Quality of Wines")
grid()
curve(predict(model5, data.frame(residual.sugar = x), type = "response"), 
      add = TRUE, col = "dodgerblue", lty = 2)

model6 = lm(quality ~ chlorides, data = training_data)
plot(quality ~ chlorides, data = training_data, xlab = "chlorides", ylab = "Quality of Wines")
grid()
curve(predict(model6, data.frame(chlorides = x), type = "response"), 
      add = TRUE, col = "dodgerblue", lty = 2)

model7 = lm(quality ~ density, data = training_data)
plot(quality ~ density, data = training_data, xlab = "density", ylab = "Quality of Wines")
grid()
curve(predict(model7, data.frame(density = x), type = "response"), 
      add = TRUE, col = "dodgerblue", lty = 2)

model8 = lm(quality ~ pH, data = training_data)
plot(quality ~ pH, data = training_data, xlab = "pH", ylab = "Quality of Wines")
grid()
curve(predict(model8, data.frame(pH = x), type = "response"), 
      add = TRUE, col = "dodgerblue", lty = 2)

model9 = lm(quality ~ sulphates, data = training_data)
plot(quality ~ sulphates, data = training_data, xlab = "sulphates", ylab = "Quality of Wines")
grid()
curve(predict(model9, data.frame(sulphates = x), type = "response"), 
      add = TRUE, col = "dodgerblue", lty = 2)

model10 = lm(quality ~ alcohol, data = training_data)
plot(quality ~ alcohol, data = training_data, xlab = "alcohol", ylab = "Quality of Wines")
grid()
curve(predict(model10, data.frame(alcohol = x), type = "response"), 
      add = TRUE, col = "dodgerblue", lty = 2)

model11 = lm(quality ~ citric.acid, data = training_data)
plot(quality ~ citric.acid, data = training_data, xlab = "citric.acid", ylab = "Quality of Wines")
grid()
curve(predict(model11, data.frame(citric.acid = x), type = "response"), 
      add = TRUE, col = "dodgerblue", lty = 2)
```

From the above graphs, we find that all those models are not performing well. It's hard to notice a conclusive pattern.   

Next, we will find the residual standard error of each model to select the best one.


```{r}
sigma = c(summary(model1)$sigma, summary(model2)$sigma, summary(model3)$sigma, summary(model4)$sigma, summary(model5)$sigma, summary(model6)$sigma, summary(model7)$sigma, summary(model8)$sigma, summary(model9)$sigma, summary(model10)$sigma, summary(model11)$sigma)

which.min(sigma)
```

We find the model uses **quality** as response and **alcohol** as predictor is the best simple linear model. 

## Multiple Linear Regression Model

Since we now know that the simple linear regression models don't work well, we will see the performance of multiple linear regression models.

### Full additive model

```{r}
full.add.model = lm(quality ~ ., data = training_data)
summary(full.add.model)
```

We conduct a significance test for the full model (above) and we find that although the residual standard error is very small, the adjusted R-squared is just 0.2967. We can declare that the full addictive model is probably not the best model. 

### Variable Selection (Forward / Backward / Exhaustive Selection with AIC & BIC) 


1. Backward Search with AIC
```{r results = FALSE}
# Backward Search with AIC
wine_mod_back_aic = step(full.add.model, direction = "backward", trace = 0)
```

```{r}
coef(wine_mod_back_aic)
```

2. Backward Search with BIC
```{r results = FALSE}
# Backward Search with BIC
n = length(resid(full.add.model))
wine_mod_back_bic = step(full.add.model, direction = "backward", trace = 0, k = log(n))
```

```{r}
coef(wine_mod_back_bic)
```

3. Forward Search with AIC
```{r results = FALSE}
# Forward Search with AIC
full.add.model.start = lm(quality ~ 1, data = training_data)
wine_mod_forw_aic = step(full.add.model.start, scope = quality ~ fixed.acidity + volatile.acidity + citric.acid + residual.sugar + chlorides + free.sulfur.dioxide + total.sulfur.dioxide + density + pH + sulphates + alcohol + type, direction = "forward")
```

```{r}
coef(wine_mod_forw_aic)
```
4. Forward Selection with BIC
```{r results = FALSE}
# Forward Selection with BIC
wine_mod_forw_bic = step(full.add.model.start, scope = quality ~ fixed.acidity + volatile.acidity + citric.acid + residual.sugar + chlorides + free.sulfur.dioxide + total.sulfur.dioxide + density + pH + sulphates + alcohol + type, direction = "forward", k = log(n))
```

```{r}
coef(wine_mod_forw_bic)
```

5. Exhaustive Search
```{r}
# Exhaustive Search
all_wine_mod = summary(regsubsets(quality ~ ., data = training_data))
best_r2_ind = which.max(all_wine_mod$adjr2)
all_wine_mod$which[best_r2_ind,]
```

```{r, warning=F}
# Exhaustive search with best AIC
p = length(coef(full.add.model))
n = length(resid(full.add.model))
best_aic = n * log(all_wine_mod$rss / n) + 2 * (2:p)
best_aic_ind = which.min(best_aic)
all_wine_mod$which[best_aic_ind,]
```

```{r}
# Exhaustive search with best BIC
best_bic = n * log(all_wine_mod$rss / n) + log(n) * (2:p)
best_bic_ind = which.min(best_bic)
all_wine_mod$which[best_bic_ind,]
```

By comparing the predictors selected by an exhaustive search, best AIC, and best BIC, we have found that they all select the same predictors, which include **fixed.acidity**, **volatile.acidity**, **residual.sugar**, **density**, **pH**, **sulphates**, **alcohol**, and **type**. 

```{r}
wine_mod_exhaustive = lm(quality ~ fixed.acidity + volatile.acidity  + residual.sugar + density + pH + sulphates + alcohol + type, data = training_data)
```


### Quadratic Models

We will fit some more complex models. 

We want to start with a big model and use backwards AIC to reduce the number of parameters.   

Before we generate a big model, we want to compare and get the best multiple linear regression model. 

```{r}
# additive model comparison
calc_loocv_rmse = function(model) {
  sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}

rmse = c(calc_loocv_rmse(full.add.model), calc_loocv_rmse(wine_mod_back_aic), calc_loocv_rmse(wine_mod_back_bic), calc_loocv_rmse(wine_mod_forw_aic), calc_loocv_rmse(wine_mod_forw_bic), calc_loocv_rmse(wine_mod_exhaustive))

r.square = c(summary(full.add.model)$adj.r.squared, summary(wine_mod_back_aic)$adj.r.squared, summary(wine_mod_back_bic)$adj.r.squared, summary(wine_mod_forw_aic)$adj.r.squared, summary(wine_mod_forw_bic)$adj.r.squared, summary(wine_mod_exhaustive)$adj.r.squared)

cbind(rmse, r.square)
```

After comparing the adjusted R-squared and LOOCV RMSE, we reach the conclusion that the model created by backward AIC selection is the best model because it has the lowest LOOCV RMSE and biggest adjusted R-squared. 

Then we can use the predictors in backward AIC model to generate a quadratic model.
```{r}
coef(wine_mod_back_aic)
```

```{r}
big_fit = lm(quality ~ . + I(fixed.acidity ^ 2) + I(volatile.acidity ^ 2) + I(residual.sugar ^ 2) + I(chlorides ^ 2) + I(free.sulfur.dioxide ^ 2) + I(total.sulfur.dioxide ^ 2) + I( density ^ 2) + I(pH ^ 2) + I(sulphates ^ 2) + I(alcohol ^ 2), data = training_data)
fit_aic = step(big_fit, direction = "backward", trace = 0)
```

```{r}
length(coef(fit_aic))
```

```{r}
summary(fit_aic)$r.sq
```

There are total 18 parameters in this model, which has a r.square = 0.3193.

### Interaction Model

As the model shown above, the first-order terms include all numeric variables besides the response and "critric.acid".

Therefore, we keep the remaining variables and build a new model by adding the two-way interactions.

```{r }
two_way_interaction_model = lm(quality ~ .^2 + I(fixed.acidity ^ 2) + I(volatile.acidity ^ 2) + I(residual.sugar ^ 2) + I(chlorides ^ 2) + I(free.sulfur.dioxide ^ 2) + I(total.sulfur.dioxide ^ 2) + I( density ^ 2) + I(pH ^ 2) + I(sulphates ^ 2) + I(alcohol ^ 2), data = training_data)

n = length(resid(two_way_interaction_model))
both_start = lm(quality ~ 1, data = training_data)

# fit stepwise aic model
both_aic = step(
  both_start, 
  scope = quality ~ .^2 + I(fixed.acidity ^ 2) + I(volatile.acidity ^ 2) + I(residual.sugar ^ 2) + I(chlorides ^ 2) + I(free.sulfur.dioxide ^ 2) + I(total.sulfur.dioxide ^ 2) + I( density ^ 2) + I(pH ^ 2) + I(sulphates ^ 2) + I(alcohol ^ 2),
  direction = "both", trace = 0)

# fit stepwise bic model
both_bic = step(
  both_start, 
  scope = quality ~ .^2 + I(fixed.acidity ^ 2) + I(volatile.acidity ^ 2) + I(residual.sugar ^ 2) + I(chlorides ^ 2) + I(free.sulfur.dioxide ^ 2) + I(total.sulfur.dioxide ^ 2) + I( density ^ 2) + I(pH ^ 2) + I(sulphates ^ 2) + I(alcohol ^ 2),
  direction = "both", k = log(n), trace = 0)
```

We then want to evaluate the efficiency of these two models.

```{r}
rmse = c(calc_loocv_rmse(both_aic), calc_loocv_rmse(both_bic))
rsqr = c(summary(both_aic)$r.square, summary(both_bic)$r.square)
cbind(rmse, rsqr)
```

```{r}
length(coef(both_aic))
```

both_aic model has the greatest r.square and smallest rmse.

Therefore, we choose the both_aic model as our interaction model.

## Classification

Given the nature of the response variable, we may expect that linear regression model will not perform very well in this case.

Therefore, we'd like to consider some classification methods.

```{r}
count(training_data, "quality")
```

From above, we see that the levels in "quality" are unevenly distributed.

Therefore, some classification methods might not perform well on the quality levels with lower frequency.

### Support Vector Machine

```{r}
training_data$quality = as.factor(training_data$quality)

svm_model = svm(quality ~., data = training_data, method = "C-classification", kernal = "radial", gamma = 0.9, cost = 15)
summary(svm_model)
```

We use the default method and kernal in this case and the model finds 4450 support vectors distributed across the classes.

1408 for "3", 1924 for "4", 768 for "5", 175 for "6", 145 for "7", 26 for "8", and 4 for "9".



# Results

From the above analysis, we have got a full additive model, a best quadratic model, a best interaction model, and a SVM model. We will use the testing data we split above to decide which model is the best.
1. Full additive model
```{r}
prediction = predict(full.add.model, testing_data)
prediction_round = round(prediction,0)
table(testing_data$quality, prediction_round)
```

From the above confusion matrix, we calculate that the accuracy is 0.534

2. Best quadratic model

```{r}
prediction2 = predict(fit_aic, testing_data)
prediction2_round = round(prediction,0)
table(testing_data$quality, prediction2_round)
```

From the above confusion matrix, we calculate that the accuracy is 0.545

3. Best interaction model

```{r}
prediction3 = predict(both_aic, testing_data)
prediction3_round = round(prediction,0)
table(testing_data$quality, prediction3_round)
```

From the above confusion matrix, we calculate that the accuracy is 0.545

4. SVM
```{r}
prediction4 = predict(svm_model, testing_data)
confusion_matrix = table(testing_data$quality, prediction4)
confusion_matrix
```

```{r}
correctPred = 0
for (i in 1:nrow(confusion_matrix)) {
  correctPred = correctPred + confusion_matrix[i, i]
}
accuracy = correctPred / nrow(testing_data)
accuracy
```

From the above confusion matrix, we calculate that the accuracy is 0.663

We conclude that SVM performs the best.

# Discussion

# Appendix
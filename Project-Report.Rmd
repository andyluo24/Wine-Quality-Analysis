---
title: "STAT 420: Final Project"
date: "12/10/2020"
output:
  html_document:
    theme: readable
    toc: yes
---

# Introduction

## Data Description

Two datasets from the Machine Learning Repository of UCI will be used for this project.

The first dataset "winequality-red" contains the red wine data in the northern Portugal area, while the second dataset "winequality-white" contains the white wine data. 

For analysis purposes, we classify all the observations based on their color types and merge them into one dataset.

The complete dataset has 6497 observations with 13 variables. 

Among the 13 variables, 12 variables are numeric attributes and 1 variable is a categorical attribute.

Numeric attributes: 

**fixed.acidity**, **volatile.acidity**, **citric.acid**, **residual.sugar**, **chlorides**, **free.sulfur.dioxide**, **total.sulfur.dioxide**, **density**, **pH**, **sulphates**, **alcohol**, **quality**   

Categorical attributes:

**Type (Red / White)**

## Project Description

Wine, as one type of alcohol, has a total consumption of 966 million in the US in 2018. 
  
Therefore, we find it may be interesting to discover the relationship between wine quality and other attributes. 
  
Then we will build a model to predict the wine quality based on those attributes. 
  
In this project, we will use "Quality" as the response variable and all other attributes as predictor variables to discover the most appropriate model.

# Methods

## Data Preprocessing

```{r dp0, message = FALSE}
# Load required packages
library(tidyverse)
library(caret)
library(leaps)

# Set seed for report consistency
set.seed(420)
```

```{r dp1}
# Import two datasets
redwine = read.csv("winequality-red.csv")
whitewine  = read.csv("winequality-white.csv")

# Add Classification "red" and "white" and merge them as one dataset
redwine$type = "red"
whitewine$type = "white"
wine = rbind(redwine, whitewine)
str(wine)
```

There are 6497 observations with 13 variables in this combined dataset.

Among 13 variables, 12 variables are numeric attributes and 1 variable is catergorical attribute.

Since the original datasets are clean-version data, we don't need to perform further data cleansing.

```{r dp2}
# Cross-validation
# 80% of the dataset for training purpose and 20% of the dataset for testing purpose
random_sample = createDataPartition(wine$quality, p = 0.8, list = FALSE)
training_data = wine[random_sample, ]
testing_data = wine[-random_sample, ]
```

## Simple Linear Regression Model and Multiple Linear Regression Model(Full Model)

```{r}
model1 = lm(quality ~ free.sulfur.dioxide, data = training_data)
plot(quality ~ free.sulfur.dioxide, data = training_data, xlab = "Free Sulfur Dioxide", ylab = "Quality of Wines")
grid()
curve(predict(model1, data.frame(free.sulfur.dioxide = x), type = "response"), 
      add = TRUE, col = "dodgerblue", lty = 2)

model2 = lm(quality ~ total.sulfur.dioxide, data = training_data)
plot(quality ~ total.sulfur.dioxide, data = training_data, xlab = "Total Sulfur Dioxide", ylab = "Quality of Wines")
grid()
curve(predict(model2, data.frame(total.sulfur.dioxide = x), type = "response"), 
      add = TRUE, col = "dodgerblue", lty = 2)

model3 = lm(quality ~ fixed.acidity, data = training_data)
plot(quality ~ fixed.acidity, data = training_data, xlab = "fixed.acidity", ylab = "Quality of Wines")
grid()
curve(predict(model3, data.frame(fixed.acidity = x), type = "response"), 
      add = TRUE, col = "dodgerblue", lty = 2)

model4 = lm(quality ~ volatile.acidity, data = training_data)
plot(quality ~ volatile.acidity, data = training_data, xlab = "volatile.acidity", ylab = "Quality of Wines")
grid()
curve(predict(model4, data.frame(volatile.acidity = x), type = "response"), 
      add = TRUE, col = "dodgerblue", lty = 2)

model5 = lm(quality ~ residual.sugar, data = training_data)
plot(quality ~ residual.sugar, data = training_data, xlab = "residual.sugar", ylab = "Quality of Wines")
grid()
curve(predict(model5, data.frame(residual.sugar = x), type = "response"), 
      add = TRUE, col = "dodgerblue", lty = 2)

model6 = lm(quality ~ chlorides, data = training_data)
plot(quality ~ chlorides, data = training_data, xlab = "chlorides", ylab = "Quality of Wines")
grid()
curve(predict(model6, data.frame(chlorides = x), type = "response"), 
      add = TRUE, col = "dodgerblue", lty = 2)

model7 = lm(quality ~ density, data = training_data)
plot(quality ~ density, data = training_data, xlab = "density", ylab = "Quality of Wines")
grid()
curve(predict(model7, data.frame(density = x), type = "response"), 
      add = TRUE, col = "dodgerblue", lty = 2)

model8 = lm(quality ~ pH, data = training_data)
plot(quality ~ pH, data = training_data, xlab = "pH", ylab = "Quality of Wines")
grid()
curve(predict(model8, data.frame(pH = x), type = "response"), 
      add = TRUE, col = "dodgerblue", lty = 2)

model9 = lm(quality ~ sulphates, data = training_data)
plot(quality ~ sulphates, data = training_data, xlab = "sulphates", ylab = "Quality of Wines")
grid()
curve(predict(model9, data.frame(sulphates = x), type = "response"), 
      add = TRUE, col = "dodgerblue", lty = 2)

model10 = lm(quality ~ alcohol, data = training_data)
plot(quality ~ alcohol, data = training_data, xlab = "alcohol", ylab = "Quality of Wines")
grid()
curve(predict(model10, data.frame(alcohol = x), type = "response"), 
      add = TRUE, col = "dodgerblue", lty = 2)
```
```{r}
summary(model1)
summary(model2)
summary(model3)
summary(model4)
summary(model5)
summary(model6)
summary(model7)
summary(model8)
summary(model9)
summary(model10)
```

After analyzing the simple linear regression models of each predictor, we find the model uses **quality** as response and **density** as predictor is significant and the slope of the regression line has the largest absolute value. As **density** increases, **quality** decreases. We will compare this model with the full addictive model. 

```{r}
library(faraway)
full.add.model = lm(quality ~ ., data = training_data)
summary(full.add.model)
```

```{r}
model_density = model7
anova(model_density, full.add.model)
```

By comparing the **model_density** and **full.add.model**, we notice that the p-value is extremely closed to 0. We conclude that we prefer the **full.add.model**, which is the full addictive model. Notwithstanding, the best model is not necessary to include all the predictors. We can conduct a significance test for the full model (above) and we find that although the residual standard error is very small, the adjusted R-squared is just 0.2967. We can declare that the full addictive model is probably not the best model. 

### Variable Selection (Forward, Backward, and Exhaustive Selection with AIC and BIC) 

```{r results = FALSE}
# Backward Search with AIC
wine_mod_back_aic = step(full.add.model, direction = "backward", trace = 0)
coef(wine_mod_back_aic)
```

```{r}
# Backward Search with BIC
n = length(resid(full.add.model))
wine_mod_back_bic = step(full.add.model, direction = "backward", trace = 0, k = log(n))
coef(wine_mod_back_bic)
```

```{r results = FALSE}
# Forward Search with AIC
full.add.model.start = lm(quality ~ 1, data = training_data)
wine_mod_forw_aic = step(full.add.model.start, scope = quality ~ fixed.acidity + volatile.acidity + citric.acid + residual.sugar + chlorides + free.sulfur.dioxide + total.sulfur.dioxide + density + pH + sulphates + alcohol + type, direction = "forward")
coef(wine_mod_forw_aic)
```

```{r results = FALSE}
# Forward Selection with BIC
wine_mod_forw_bic = step(full.add.model.start, scope = quality ~ fixed.acidity + volatile.acidity + citric.acid + residual.sugar + chlorides + free.sulfur.dioxide + total.sulfur.dioxide + density + pH + sulphates + alcohol + type, direction = "forward", k = log(n))
```

```{r}
coef(wine_mod_forw_bic)
```

```{r}
# Exhaustive Search
all_wine_mod = summary(regsubsets(quality ~ ., data = training_data))
all_wine_mod$which
```

```{r}
(best_r2_ind = which.max(all_wine_mod$adjr2))
all_wine_mod$which[best_r2_ind,]
```

```{r}
# Exhaustive search with best AIC
p = length(coef(full.add.model))
n = length(resid(full.add.model))
best_aic = n * log(all_wine_mod$rss / n) + 2 * (2:p)
best_aic_ind = which.min(best_aic)
all_wine_mod$which[best_aic_ind,]
```

```{r}
# Exhaustive search with best BIC
best_bic = n * log(all_wine_mod$rss / n) + log(n) * (2:p)
best_bic_ind = which.min(best_bic)
all_wine_mod$which[best_bic_ind,]
```

By comparing the predictors selected by an exhaustive search, best AIC, and best BIC, we have found that they all select the same predictors, which include **fixed.acidity**, **volatile.acidity**, **residual.sugar**, **density**, **pH**, **sulphates**, **alcohol**, and **type**. 

```{r}
wine_mod_exhaustive = lm(quality ~ fixed.acidity + volatile.acidity  + residual.sugar + density + pH + sulphates + alcohol + type, data = training_data)
```

```{r}
# addictive model comparison
calc_loocv_rmse = function(model) {
  sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}

calc_loocv_rmse(full.add.model)
calc_loocv_rmse(wine_mod_back_aic)
calc_loocv_rmse(wine_mod_back_bic)
calc_loocv_rmse(wine_mod_forw_aic)
calc_loocv_rmse(wine_mod_forw_bic)
calc_loocv_rmse(wine_mod_exhaustive)

summary(full.add.model)$adj.r.squared
summary(wine_mod_back_aic)$adj.r.squared
summary(wine_mod_back_bic)$adj.r.squared
summary(wine_mod_forw_aic)$adj.r.squared
summary(wine_mod_forw_bic)$adj.r.squared
summary(wine_mod_exhaustive)$adj.r.squared
```

After comparing the adjusted R-squared and LOOCV RMSE, we reach the conclusion that the model created by backward AIC selection is the best model because it has the lowest LOOCV RMSE and biggest adjusted R-squared.   

## Quadratic Models

```{r}

```

### Interaction Model

```{r IM0}
# Reproduce the training_data and factor the dummy variable "type"
training_data_IM = training_data
training_data_IM$type = as.factor(training_data_IM$type)
four_way_interaction_model = lm(quality ~ .^4, data = training_data_IM)
three_way_interaction_model = lm(quality ~ .^3, data = training_data_IM)
two_way_interaction_model = lm(quality ~ .^2, data = training_data_IM)
one_way_interaction_model = lm(quality ~ ., data = training_data_IM)
```

```{r IM1}
anova(one_way_interaction_model, two_way_interaction_model)$"Pr(>F)"[2]
```

Since p-value is smaller than 0.05, we reject the null hypothesis and conclude that the "two_way_interaction_model" is better.

```{r IM2}
anova(two_way_interaction_model, three_way_interaction_model)$"Pr(>F)"[2]
```

Since p-value is smaller than 0.05, we reject the null hypothesis and conclude that the "three_way_interaction_model" is better.

```{r IM3}
anova(three_way_interaction_model, four_way_interaction_model)$"Pr(>F)"[2]
```

Since p-value is smaller than 0.05, we reject the null hypothesis and conclude that the "four_way_interaction_model" is better.

We will leave this model for future comparisons with other potential models.

### To add on

```{r }

```

# Results

# Discussion

# Appendix
---
title: "Wine Quality Prediction Project"
output:
  html_document:
    theme: readable
    toc: yes
---

# Introduction

## Data Description

Two [datasets](https://archive.ics.uci.edu/ml/datasets/wine+quality) from the Machine Learning Repository of UCI will be used for this project. The first dataset "winequality-red" contains the red wine data in the northern Portugal area, while the second dataset "winequality-white" contains the white wine data. For analysis purposes, we classify all the observations based on their color types and merge them into one dataset. The complete dataset has 6497 observations with 13 variables. Among the 13 variables, 12 variables are numeric attributes and 1 variable is a categorical attribute.

Numeric attributes: 

- `fixed.acidity`: Most acids involved with wine or fixed or nonvolatile (do not evaporate readily).
- `volatile.acidity`: The amount of acetic acid in wine, which at too high of levels can lead to an unpleasant, vinegar taste.
- `citric.acid`: Found in small quantities, citric acid can add 'freshness' and flavor to wines.
- `residual.sugar`: The amount of sugar remaining after fermentation stops.
- `chlorides`: The amount of salt in the wine.
- `free.sulfur.dioxide`: The free form of SO2 exists in equilibrium between molecular SO2 (as a dissolved gas) and bisulfite ion.
- `total.sulfur.dioxide`: Amount of free and bound forms of S02;in low concentrations, SO2 is mostly undetectable in wine, but at free SO2 concentrations over 50 ppm, SO2 becomes evident in the nose and taste of wine.
- `density`: The density of water is close to that of water depending on the percent alcohol and sugar content.
- `pH`: Describes how acidic or basic a wine is on a scale from 0 (very acidic) to 14 (very basic);most wines are between 3-4 on the pH scale.
- `sulphates`: A wine additive which can contribute to sulfur dioxide gas (S02) levels, which acts as an antimicrobial and antioxidant.
- `alcohol`: The percent alcohol content of the wine.
- `quality`: Output variable.   

Categorical attributes:

- `Type`: Red / White.

## Project Description

Wine, as one type of alcohol, has a total consumption of 966 million in the US in 2018. Therefore, we find it may be interesting to discover the relationship between wine quality and other attributes. Then we will build a model to predict the wine quality based on those attributes. In this project, we will use "Quality" as the response variable and all other attributes as predictor variables to discover the most appropriate model.

# Methods

## Data Preprocessing

```{r dp0, include = FALSE}
# Load required packages
library(PerformanceAnalytics)
library(tidyverse)
library(caret)
library(leaps)
library(faraway)
library(e1071)
# Set seed for report consistency
set.seed(420)
```

```{r dp1}
# Import two datasets
redwine = read.csv("winequality-red.csv")
whitewine  = read.csv("winequality-white.csv")

# Add Classification "red" and "white" and merge them as one dataset
redwine$type = "red"
whitewine$type = "white"
wine = rbind(redwine, whitewine)
str(wine)
```

There are 6497 observations with 13 variables in this combined dataset.

Among 13 variables, 12 variables are numeric attributes and 1 variable is catergorical attribute.

Since the original datasets are clean-version data, we don't need to perform further data cleansing.

```{r dp2}
# Cross-validation
# 80% of the dataset for training purpose and 20% of the dataset for testing purpose
random_sample = createDataPartition(wine$quality, p = 0.8, list = FALSE)
training_data = wine[random_sample, ]
testing_data = wine[-random_sample, ]
```

We split the original data, using 80% of the data for training and 20% of the data for testing.

## Simple Linear Regression Model 

First, we try to use simple linear regression to check if the wine quality is closely connected to one attribute. 
Here is the chart for correlation among all variables except type.

```{r}
chart.Correlation(training_data[, 1:12], histogram = TRUE, pch = 19)
```

From the above graph, we find that it's hard to notice a conclusive pattern.

But we still find that the correlation between free.sulfur.dioxide and all.sulfur.dioxide is high, which adhere to our intuition.

Also, we discover that the correlation between quality and alcohol is 0.45, which is the highest compared to other predictors.

```{r}
model1 = lm(quality ~ free.sulfur.dioxide, data = training_data)
model2 = lm(quality ~ total.sulfur.dioxide, data = training_data)
model3 = lm(quality ~ fixed.acidity, data = training_data)
model4 = lm(quality ~ volatile.acidity, data = training_data)
model5 = lm(quality ~ residual.sugar, data = training_data)
model6 = lm(quality ~ chlorides, data = training_data)
model7 = lm(quality ~ density, data = training_data)
model8 = lm(quality ~ pH, data = training_data)
model9 = lm(quality ~ sulphates, data = training_data)
model10 = lm(quality ~ alcohol, data = training_data)
model11 = lm(quality ~ citric.acid, data = training_data)
```

To compare these models in a more visualized way, we will compare the residual standard error and R-squared of each model to select the best one.

```{r}
sigma.list = c(summary(model1)$sigma, summary(model2)$sigma, summary(model3)$sigma, summary(model4)$sigma, summary(model5)$sigma, summary(model6)$sigma, summary(model7)$sigma, summary(model8)$sigma, summary(model9)$sigma, summary(model10)$sigma, summary(model11)$sigma)

r.squared.list = c(summary(model1)$r.squared, summary(model2)$r.squared, summary(model3)$r.squared, summary(model4)$r.squared, summary(model5)$r.squared, summary(model6)$r.squared, summary(model7)$r.squared, summary(model8)$r.squared, summary(model9)$r.squared, summary(model10)$r.squared, summary(model11)$r.squared)

(data1 = data.frame(residual.standard.error = sigma.list, R.squared = r.squared.list))
```

We find the model uses **quality** as response and **alcohol** as predictor is the best simple linear model, because this model has the highest R-squared and lowest residual standard error. 

```{r}
summary(model10)
```

We conducted a significance test for this best simple linear regression model and the p-value is extremely closed to 0. Thus, we conclude that this model is significant and **alcohol** is a significant predictor. 

## Multiple Linear Regression Model

We would like to build a full addictive model that takes **quality** as response and all the other variables as predictors.

```{r}
full.add.model = lm(quality ~ ., data = training_data)
summary(full.add.model)
```

The p-value of the model is less than 0.05. Therefore, we reject the null hypothesis and conclude that at least one of the predictors is significant in explaining the response. We would like to compare the best simple linear regression model and this full addictive model to find the better of these two models. 

```{r}
model_alcohol = model10
anova(model_alcohol, full.add.model)
```

By comparing the **model_alcohol** and **full.add.model**, we notice that the p-value is extremely closed to 0. We conclude that we prefer the **full.add.model**, which is the full addictive model. However, the best model is not necessary to include all the predictors. We conduct a significance test for the full model (above) and we find that although the residual standard error is very small, the adjusted R-squared is just 0.2967. We can state that the full addictive model is probably not the best model. 

### Forward / Backward / Exhaustive Selection with AIC & BIC

We use backward selection with AIC and BIC to construct two new models and we will also use exhaustive search with best AIC and BIC to build a number of models and select the best model among these models. 

```{r results = FALSE}
# Backward Search with AIC
wine_mod_back_aic = step(full.add.model, direction = "backward", trace = 0)
```

```{r}
# Backward Search with BIC
n = length(resid(full.add.model))
wine_mod_back_bic = step(full.add.model, direction = "backward", trace = 0, k = log(n))
```

```{r}
# Forward Search with AIC
full.add.model.start = lm(quality ~ 1, data = training_data)
wine_mod_forw_aic = step(full.add.model.start, scope = quality ~ fixed.acidity + volatile.acidity + citric.acid + residual.sugar + chlorides + free.sulfur.dioxide + total.sulfur.dioxide + density + pH + sulphates + alcohol + type, direction = "forward", trace = 0)
```

```{r}
# Forward Selection with BIC
wine_mod_forw_bic = step(full.add.model.start, scope = quality ~ fixed.acidity + volatile.acidity + citric.acid + residual.sugar + chlorides + free.sulfur.dioxide + total.sulfur.dioxide + density + pH + sulphates + alcohol + type, direction = "forward", k = log(n), trace = 0)
```

```{r}
# Exhaustive Search
all_wine_mod = summary(regsubsets(quality ~ ., data = training_data))
best_r2_ind = which.max(all_wine_mod$adjr2)
```

```{r, warning=F}
# Exhaustive search with best AIC
p = length(coef(full.add.model))
n = length(resid(full.add.model))
best_aic = n * log(all_wine_mod$rss / n) + 2 * (2:p)
best_aic_ind = which.min(best_aic)
all_wine_mod$which[best_aic_ind,]
```

The exhaustive search model with AIC contains the variables fixed.acidity, volatile.acidity, residual.sugar, density, pH, sulphates, alcohol, and type.

```{r, warning=F}
# Exhaustive search with best BIC
best_bic = n * log(all_wine_mod$rss / n) + log(n) * (2:p)
best_bic_ind = which.min(best_bic)
all_wine_mod$which[best_bic_ind,]
```

By comparing the predictors selected by an exhaustive search, best AIC, and best BIC, we have found that they all select the same predictors, which include **fixed.acidity**, **volatile.acidity**, **residual.sugar**, **density**, **pH**, **sulphates**, **alcohol**, and **type**. 

```{r}
# model selected by the exhaustive search
wine_mod_exhaustive = lm(quality ~ fixed.acidity + volatile.acidity  + residual.sugar + density + pH + sulphates + alcohol + type, data = training_data)
```

We will fit some more complex models. 

We want to start with a big model and use backwards AIC to reduce the number of parameters.   

Before we generate a big model, we want to compare and get the best multiple linear regression model. 

```{r}
# additive model comparison
calc_loocv_rmse = function(model) {
  sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}
rmse = c(calc_loocv_rmse(full.add.model), calc_loocv_rmse(wine_mod_back_aic), calc_loocv_rmse(wine_mod_back_bic), calc_loocv_rmse(wine_mod_forw_aic), calc_loocv_rmse(wine_mod_forw_bic), calc_loocv_rmse(wine_mod_exhaustive))
r.square = c(summary(full.add.model)$adj.r.squared, summary(wine_mod_back_aic)$adj.r.squared, summary(wine_mod_back_bic)$adj.r.squared, summary(wine_mod_forw_aic)$adj.r.squared, summary(wine_mod_forw_bic)$adj.r.squared, summary(wine_mod_exhaustive)$adj.r.squared)
cbind(rmse, r.square)
```

After comparing the adjusted R-squared and LOOCV RMSE, we notice that the models selected by the forward and backward selection with AIC, **wine_mod_back_aic** and **wine_mod_forw_aic**, are identical because they have the same predictors, R-squared, and LOOCV RMSE. **wine_mod_back_aic** has the lowest LOOCV RMSE and biggest adjusted R-squared. However, its number of predictors are more than **wine_mod_exhaustive**. 

```{r}
cbind(length(coef(wine_mod_back_aic)),length(coef(wine_mod_exhaustive)))
```

And we notice that the LOOCV RMSE and R-squared of these two models are very closed. Thus, we decide to adopt the one with less predictors as the best model so far, **wine_mod_exhaustive**. 

### Quadratic Model

In the **wine_mod_exhaustive** model, there are only first-order terms. Next, we will consider polynomial terms. We will put the predictors of **wine_mod_exhaustive** into quadratic forms and compare the new model with **wine_mod_exhaustive**. 

```{r}
coef(wine_mod_exhaustive) # predictors of wine_mod_exhaustive
```

```{r}
wine_mod_exhaustive_quad = lm(quality ~ . + I(fixed.acidity ^ 2) + I(volatile.acidity ^ 2) + I(residual.sugar ^ 2) + I(density ^ 2) + I(pH ^ 2) + I(sulphates ^ 2) + I(alcohol ^ 2), data = training_data)
summary(wine_mod_exhaustive_quad)
```

It is clear that not all of the predictors are significant. Thus, we will use backward AIC selection to create a new model. 

```{r}
wine_mod_exhaustive_quad_aic = step(wine_mod_exhaustive_quad, direction = "backward", trace = 0)
```

```{r}
anova(wine_mod_exhaustive_quad_aic, wine_mod_exhaustive_quad)
```

The p-value, 0.477, indicates that we will prefer the smaller model, **wine_mod_exhaustive_quad_aic**. 

### Interaction Model

```{r}
coef(wine_mod_exhaustive)
```

The **wine_mod_exhaustive** model contains **fixed.acidity**, **volatile.acidity**, **residual.sugar**, **density**, **pH**, **sulphates**, **alcohol**, and **type** as predictors. We will consider the two-way interactions between these predictors and add these terms to **wine_mod_exhaustive_quad_aic** to construct a new model. 

```{r }
two_way_interaction_model = lm(quality ~ (fixed.acidity + volatile.acidity + residual.sugar + density + pH + sulphates + alcohol + type)^2 + I(fixed.acidity^2) + I(volatile.acidity^2) + I(residual.sugar^2) + I(density^2) + I(pH^2) + I(sulphates^2) + I(alcohol^2), data = training_data)
summary(two_way_interaction_model)
```

It looks like there are many redundant insignificant terms in this model. 

We then use backward selection with AIC to create a new model.

```{r}
int_aic = step(two_way_interaction_model, direction = "backward", trace = 0)
```

We then want to compare these two models to find out the better one. 

```{r}
anova(int_aic, two_way_interaction_model)
```

After the comparison, the large p-value, 0.7799, suggests that we prefer the model **int_aic**. 

## Classification

Given the nature of the response variable, we may expect that linear regression model will not perform very well in this case.

Therefore, we'd like to consider some classification methods.

```{r}
t = as.data.frame(table(training_data$quality))
t
count(training_data, "quality")
```

From above, we see that the levels in "quality" are unevenly distributed.

Therefore, some classification methods might not perform well on the quality levels with lower frequency.

### Support Vector Machine

```{r}
training_data$quality = as.factor(training_data$quality)
svm_model = svm(quality ~., data = training_data, method = "C-classification", kernal = "radial", gamma = 0.9, cost = 15)
summary(svm_model)
```

We use the default method and kernal in this case and the model finds 4450 support vectors distributed across the classes.

1408 for "3", 1924 for "4", 768 for "5", 175 for "6", 145 for "7", 26 for "8", and 4 for "9".

# Results

We would like to use the adjusted R-squared, LOOCV RMSE, AIC value, and number of terms of models to the testing data as standards to select the best model among the linear regression and interaction models. 

```{r}
adjusted.r.squared = c(summary(int_aic)$adj.r.squared, summary(two_way_interaction_model)$adj.r.squared, summary(wine_mod_exhaustive_quad_aic)$adj.r.squared, summary(wine_mod_exhaustive_quad)$adj.r.squared, summary(wine_mod_exhaustive)$adj.r.squared, summary(full.add.model)$adj.r.squared, summary(wine_mod_back_aic)$adj.r.squared, summary(wine_mod_back_bic)$adj.r.squared, summary(wine_mod_forw_aic)$adj.r.squared, summary(wine_mod_forw_bic)$adj.r.squared, summary(model_alcohol)$adj.r.squared)

rmse = c(calc_loocv_rmse(int_aic), calc_loocv_rmse(two_way_interaction_model), calc_loocv_rmse(wine_mod_exhaustive_quad_aic), calc_loocv_rmse(wine_mod_exhaustive_quad), calc_loocv_rmse(wine_mod_exhaustive), calc_loocv_rmse(full.add.model), calc_loocv_rmse(wine_mod_back_aic), calc_loocv_rmse(wine_mod_back_bic), calc_loocv_rmse(wine_mod_forw_aic), calc_loocv_rmse(wine_mod_forw_bic), calc_loocv_rmse(model_alcohol))

aic = c(extractAIC(int_aic)[2], extractAIC(two_way_interaction_model)[2], extractAIC(wine_mod_exhaustive_quad_aic)[2], extractAIC(wine_mod_exhaustive_quad)[2], extractAIC(wine_mod_exhaustive)[2], extractAIC(full.add.model)[2], extractAIC(wine_mod_back_aic)[2], extractAIC(wine_mod_back_bic)[2], extractAIC(wine_mod_forw_aic)[2], extractAIC(wine_mod_forw_bic)[2], extractAIC(model_alcohol)[2])

term_number = c(length(coef(int_aic)), length(coef(two_way_interaction_model)), length(coef(wine_mod_exhaustive_quad_aic)), length(coef(wine_mod_exhaustive_quad)), length(coef(wine_mod_exhaustive)), length(coef(full.add.model)), length(coef(wine_mod_back_aic)), length(coef(wine_mod_back_bic)), length(coef(wine_mod_forw_aic)), length(coef(wine_mod_forw_bic)), length(coef(model_alcohol)))

models = c("int_aic", "two_way_interaction_model", "wine_mod_exhaustive_quad_aic", "wine_mod_exhaustive_quad", "wine_mod_exhaustive", "full.add.model", "wine_mod_back_aic", "wine_mod_back_bic", "wine_mod_forw_aic", "wine_mod_forw_bic", "model_alcohol")

cbind(models, adjusted.r.squared, rmse, aic, term_number)
```

By looking at the table above, we can see that the models **int_aic** has the best performance since **int_aic** has the highest adjusted R-squared, the lowest LOOCV RMSE, and smallest AIC. However, it has relatively larger number of terms comparing to **wine_mod_exhaustive_quad_aic**, which has similar values of the three aforementioned standards. We would like to investigate how accurate these two models can have on the testing data. 

```{r}
accur <- function(list1, list2) {
  if (length(list1) != length(list2)) {
    stop()
  }
  list1 = round(list1,0)
  list2 = round(list2,0)
  n = length(list1)
  count = 0
  for (i in 1:n) {
    if (list1[i] == list2[i]) {
      count = count + 1
    }
  }
  accuracy = count/n
  return(accuracy)
}

prediction1 = predict(int_aic, testing_data)
prediction2 = predict(wine_mod_exhaustive_quad_aic, testing_data)
accuracy1 = accur(testing_data$quality, prediction1)
accuracy2 = accur(testing_data$quality, prediction2)
cbind(accuracy1, accuracy2)
```

The **int_aic** has a higher accuracy than **wine_mod_exhaustive_quad_aic**. We prefer **int_aic** as the best model among the linear regression and interaction models. We also would like to compare the accuracy between classification method and **int_aic**, specifically the support vector machine method.

```{r}
prediction3 = predict(svm_model, testing_data)
confusion_matrix = table(testing_data$quality, prediction3)
confusion_matrix
```

```{r}
correctPred = 0
for (i in 1:nrow(confusion_matrix)) {
  correctPred = correctPred + confusion_matrix[i, i]
}
accuracy = correctPred / nrow(testing_data)
accuracy
```

From the above confusion matrix, we calculate that the accuracy is 0.663, which is larger than the accuracy of **int_aic**. 

We conclude that SVM and **int_aic** are the best two final models. 

# Discussion

Different from the traditional, relying on human tasting to judge the quality of wines, our analysis quantifies the characteristics of wine and utilizes statistical models to draw conclusions. In today's wine market, there are so many varieties of wine that consumers often feel unable to start. Our models and result provide customers with a reference.  

According to our model and analysis, it can be seen that there are some characteristics that have a relatively large impact on the quality of wines. Among the predictors that we find, **alcohol** is the most significant predictor. Thus, our model indicates that when consumers are purchasing wines, they should pay more attention to the amount of alcohol that wines contain. Wine producers should also take the amount of alcohol into consideration when brewing wines or trying to explore new wine products. The amount of alcohol can decide the quality to some degree, and will subsequently influence the wine sales and incomes of wine producers. Another predictor that we should pay special attention to is the **density**. Not only our final model contains this predictor, but also the simple linear regression model that solely includes this variable as the predictor shows a regression line with the largest slope (in absolute value). The simple linear regression model shows that the higher the density, the worse the quality of wines. We know that the definition of density as mentioned in the introduction section states that density indicates the amount of sugar and alcohol in the alcohol. When authenticating and evaluating the quality of wines, the density of wines should be paid special attention by wine experts and connoisseurs. 

For the remaining features, we can consider ignoring them in the future data collection process. This will not only simplify the data collection process but also improve our accuracy of judgment. Moreover, in this experiment, we rounded our prediction of quality to compare it with the original data. After confirming that our model is reliable, we can keep the decimal places to have a better assessment of the quality of wines. 

# Appendix
## Accuracy table
Here we are going to show the prediction accuracy of all models discussed above. 
```{r}
all_models = c("int_aic", "two_way_interaction_model", "wine_mod_exhaustive_quad_aic", "wine_mod_exhaustive_quad", "wine_mod_exhaustive", "full.add.model", "wine_mod_back_aic", "wine_mod_back_bic", "wine_mod_forw_aic", "wine_mod_forw_bic", "model_alcohol", "SVM")
all_accuracy = c(accur(testing_data$quality, predict(int_aic, testing_data)), accur(testing_data$quality, predict(two_way_interaction_model, testing_data)), accur(testing_data$quality, predict(wine_mod_exhaustive_quad_aic, testing_data)), accur(testing_data$quality, predict(wine_mod_exhaustive_quad, testing_data)), accur(testing_data$quality, predict(wine_mod_exhaustive, testing_data)), accur(testing_data$quality, predict(full.add.model, testing_data)), accur(testing_data$quality, predict(wine_mod_back_aic, testing_data)), accur(testing_data$quality, predict(wine_mod_back_bic, testing_data)), accur(testing_data$quality, predict(wine_mod_forw_aic, testing_data)), accur(testing_data$quality, predict(wine_mod_forw_bic, testing_data)), accur(testing_data$quality, predict(model_alcohol, testing_data)),
accuracy)
all_accuracy = cbind(all_models, all_accuracy)
all_accuracy
```

## Group Number 
Eric Lu (cunyuan2)   
Andy Luo (yuhuail2)   
Ted Chen (jundong2)  
Dali Su (dalisu2)   
